<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Snapchat-Like Glasses Filter</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    #video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: auto;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    #glasses-options {
      position: fixed;
      bottom: 20px;
      left: 20px;
      background: rgba(255, 255, 255, 0.8);
      padding: 10px;
      border-radius: 10px;
      display: flex;
      gap: 10px;
    }
    #glasses-options img {
      width: 80px;
      cursor: pointer;
      border: 2px solid transparent;
      border-radius: 5px;
    }
    #glasses-options img.selected {
      border-color: #007bff;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted></video>
  <canvas id="overlay"></canvas>
  <div id="glasses-options">
    <img src="glasses1.png" alt="Glasses 1" onclick="selectGlasses('glasses1.png')">
    <img src="glasses2.png" alt="Glasses 2" onclick="selectGlasses('glasses2.png')">
  </div>

  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const glassesOptions = document.querySelectorAll('#glasses-options img');
    let selectedGlasses = null;
    const ctx = canvas.getContext('2d');

    // Select glasses to apply
    function selectGlasses(glassesSrc) {
      selectedGlasses = new Image();
      selectedGlasses.src = glassesSrc;

      // Update UI
      glassesOptions.forEach(option => option.classList.remove('selected'));
      const clickedOption = Array.from(glassesOptions).find(option => option.src.includes(glassesSrc));
      if (clickedOption) clickedOption.classList.add('selected');
    }

    // Start the video stream
    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.play();
    }

    // Load FaceAPI models
    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
      detectFace();
    }

    // Detect face landmarks
    async function detectFace() {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        if (detections && selectedGlasses) {
          const landmarks = detections.landmarks;
          const nose = landmarks.getNose();
          const leftEye = landmarks.getLeftEye();
          const rightEye = landmarks.getRightEye();

          // Calculate glasses position and size
          const glassesWidth = Math.abs(rightEye[0].x - leftEye[3].x) * 2;
          const glassesHeight = glassesWidth / 2;
          const glassesX = nose[0].x - glassesWidth / 2;
          const glassesY = nose[0].y - glassesHeight / 2;

          // Draw glasses
          ctx.drawImage(selectedGlasses, glassesX, glassesY, glassesWidth, glassesHeight);
        }
      }, 100);
    }

    // Start everything
    startVideo();
    loadModels();
  </script>
</body>
</html>
